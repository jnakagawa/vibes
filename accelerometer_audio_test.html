<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Speed Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #333;
            color: white;
            text-align: center;
            padding: 20px;
        }
        button {
            padding: 20px;
            font-size: 20px;
            margin: 10px;
        }
        #character {
            font-size: 20vh;
            margin: 20px;
        }
    </style>
</head>
<body>
    <h1>Simple Audio Test</h1>
    <button onclick="startAudio()">START AUDIO</button>
    <button onclick="stopAudio()">STOP</button>
    <div>Speed: <span id="speed">1.0</span>x</div>
    <div id="character">観</div>
    
    <script>
        let audioContext;
        let audioBuffer;
        let source;
        let isPlaying = false;
        let startTime = 0;
        let playbackPosition = 0;
        let useGranular = false;
        
        const hanyaText = '觀自在菩薩行深般若波羅密多時照見五蘊皆空度一切苦厄舍利子色不異空空不異色色即是空空即是色受想行識亦復如是舍利子是諸法空相不生不滅不垢不淨不增不減是故空中無色無受想行識無眼耳鼻舌身意無色聲香味觸法無眼界乃至無意識界無無明亦無無明盡乃至無老死亦無老死盡無苦集滅道無智亦無得以無所得故菩提薩埵依般若波羅密多故心無罣礙無罣礙故無有恐怖遠離顛倒夢想究竟涅槃三世諸佛依般若波羅密多故得阿耨多羅三藐三菩提故知般若波羅密多是大神咒是大明咒是無上咒是無等等咒能除一切苦真實不虛故說般若波羅密多咒即說咒曰揭諦揭諦波羅揭諦波羅僧揭諦菩提薩婆訶摩訶般若波羅密多';
        let speed = 1.0;
        
        async function loadAudio() {
            try {
                audioContext = new AudioContext();
                const response = await fetch('tools/vocal.mp3');
                const data = await response.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(data);
                console.log('Audio loaded');
            } catch (e) {
                console.error('Failed to load audio:', e);
            }
        }
        
        function startAudio() {
            if (!audioBuffer) {
                loadAudio().then(() => startAudio());
                return;
            }
            
            if (audioContext.state === 'suspended') {
                audioContext.resume();
            }
            
            // Initialize granular system
            if (!masterGain) {
                initGranular();
            }
            
            startTime = audioContext.currentTime;
            playbackPosition = 0;
            nextGrainTime = audioContext.currentTime + 0.1; // Start slightly ahead
            isPlaying = true;
            
            // Start granular playback
            scheduleGrains();
            
            // Start character update loop
            updateCharacters();
            console.log('Audio started');
        }
        
        function updateCharacters() {
            if (!isPlaying) return;
            
            // Calculate current position in the audio based on speed
            const elapsed = (audioContext.currentTime - startTime) * speed;
            playbackPosition = elapsed % audioBuffer.duration;
            
            // Map position to character index
            const progress = playbackPosition / audioBuffer.duration;
            const charIndex = Math.floor(progress * hanyaText.length);
            document.getElementById('character').textContent = hanyaText[charIndex] || '観';
            
            requestAnimationFrame(updateCharacters);
        }
        
        function stopAudio() {
            if (source) {
                source.stop();
                source = null;
            }
            isPlaying = false;
        }
        
        // Auto-load on page load
        loadAudio();
        
        // Better granular approach
        let grainSize = 0.1; // 100ms grains - not too small to avoid garbling
        let grainOverlap = 0.5; // 50% overlap
        let nextGrainTime = 0;
        let masterGain;
        
        function initGranular() {
            masterGain = audioContext.createGain();
            masterGain.gain.value = 0.6;
            masterGain.connect(audioContext.destination);
        }
        
        function scheduleGrains() {
            if (!isPlaying || !audioBuffer) return;
            
            const now = audioContext.currentTime;
            let grainsScheduled = 0;
            
            // Schedule grains, but not too many at once
            while (nextGrainTime < now + 0.3 && grainsScheduled < 5) {
                const grain = audioContext.createBufferSource();
                grain.buffer = audioBuffer;
                grain.playbackRate.value = 0.8; // Keep pitch 20% lower
                
                // Simple envelope - less complex to avoid garbling
                const grainEnv = audioContext.createGain();
                const startTime = nextGrainTime;
                
                // Gentle fade in/out
                grainEnv.gain.setValueAtTime(0, startTime);
                grainEnv.gain.linearRampToValueAtTime(0.5, startTime + 0.02);
                grainEnv.gain.setValueAtTime(0.5, startTime + grainSize - 0.02);
                grainEnv.gain.linearRampToValueAtTime(0, startTime + grainSize);
                
                grain.connect(grainEnv);
                grainEnv.connect(masterGain);
                
                // Start grain at current playback position
                const offset = playbackPosition % audioBuffer.duration;
                try {
                    grain.start(startTime, offset, grainSize);
                    grainsScheduled++;
                } catch (e) {
                    // Skip this grain if there's an error
                }
                
                // Move playback position forward based on current speed
                playbackPosition += grainSize * speed;
                
                // Schedule next grain
                nextGrainTime += grainSize * (1 - grainOverlap);
            }
            
            // Keep scheduling - longer intervals for stability
            if (isPlaying) {
                setTimeout(scheduleGrains, 50);
            }
        }
        
        // Test accelerometer
        if (window.DeviceMotionEvent) {
            window.addEventListener('devicemotion', (e) => {
                if (e.accelerationIncludingGravity && isPlaying) {
                    const z = e.accelerationIncludingGravity.z || 0;
                    
                    // Map Z axis to speed: face down (z ≈ +10) = 0.1x, face up (z ≈ -10) = 100x
                    let normalizedZ = (z + 10) / 20; // Normalize to 0-1
                    normalizedZ = Math.max(0, Math.min(1, normalizedZ));
                    normalizedZ = 1 - normalizedZ; // Invert so face down is slow
                    
                    // Exponential scale: 0.1x to 100x
                    const minSpeed = 0.1;
                    const maxSpeed = 100;
                    speed = minSpeed * Math.pow(maxSpeed / minSpeed, normalizedZ);
                    
                    document.getElementById('speed').textContent = speed.toFixed(1);
                }
            });
        }
    </script>
</body>
</html>