<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Sound Catcher</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: #0a0a0a;
            color: #e0e0e0;
            overflow: hidden;
            touch-action: none;
            width: 100vw;
            height: 100vh;
        }

        #app {
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
        }

        #layers-container {
            flex: 1;
            overflow-y: auto;
            overflow-x: hidden;
            position: relative;
            padding-bottom: 80px;
        }

        .layer {
            width: 100%;
            position: relative;
            border-bottom: 1px solid #222;
            display: flex;
        }

        .layer-canvas-container {
            flex: 1;
            position: relative;
            min-height: 120px;
        }

        .layer canvas {
            width: 100%;
            height: 100%;
            display: block;
        }

        .layer-controls {
            width: 60px;
            background: #111;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 10px 5px;
            gap: 10px;
        }

        .volume-slider {
            writing-mode: bt-lr;
            -webkit-appearance: slider-vertical;
            width: 30px;
            height: 100px;
            flex-shrink: 0;
        }

        .layer-button {
            width: 44px;
            height: 44px;
            border: 1px solid #444;
            background: #1a1a1a;
            color: #e0e0e0;
            border-radius: 6px;
            font-size: 11px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            flex-shrink: 0;
        }

        .layer-button:active {
            background: #2a2a2a;
        }

        .selection-overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            pointer-events: none;
        }

        .selection-handle {
            position: absolute;
            top: 20%;
            bottom: 20%;
            width: 4px;
            background: #00ffff;
            cursor: ew-resize;
            pointer-events: auto;
            z-index: 10;
            box-shadow: 0 0 6px rgba(0, 255, 255, 0.8);
        }

        .selection-handle::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 44px;
            height: 60px;
            background: transparent;
            pointer-events: auto;
        }

        .selection-handle::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 16px;
            height: 16px;
            background: #000;
            border: 2px solid #00ffff;
            border-radius: 50%;
            box-shadow: 0 0 8px rgba(0, 255, 255, 0.6);
        }

        .selection-dim {
            position: absolute;
            top: 0;
            bottom: 0;
            background: rgba(10, 10, 10, 0.7);
            pointer-events: none;
        }

        .axis-container {
            position: absolute;
            top: 0;
            left: 0;
            right: 60px;
            bottom: 0;
            pointer-events: none;
        }

        .axis-y {
            position: absolute;
            left: 0;
            top: 0;
            bottom: 0;
            width: 50px;
            border-right: 1px solid #333;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            padding: 5px 2px;
        }

        .axis-y-label {
            font-size: 9px;
            color: #666;
            text-align: right;
            padding-right: 3px;
        }

        .axis-x {
            position: absolute;
            left: 50px;
            right: 0;
            bottom: 0;
            height: 20px;
            border-top: 1px solid #333;
            display: flex;
            justify-content: space-between;
            padding: 2px 5px;
        }

        .axis-x-label {
            font-size: 9px;
            color: #666;
        }

        .empty-state {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 18px;
            color: #444;
            text-align: center;
            pointer-events: none;
        }

        #playback-indicator {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            transform-style: preserve-3d;
            pointer-events: none;
            z-index: 100;
            opacity: 0;
            transition: opacity 0.3s, transform 0.1s ease-out;
        }

        #playback-indicator.active {
            opacity: 1;
        }

        #toolbar {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            height: 80px;
            background: #111;
            border-top: 1px solid #333;
            display: flex;
            align-items: center;
            justify-content: space-around;
            padding: 10px;
            z-index: 50;
        }

        .toolbar-button {
            width: 60px;
            height: 60px;
            border: 2px solid #444;
            background: #1a1a1a;
            color: #e0e0e0;
            border-radius: 50%;
            font-size: 12px;
            cursor: pointer;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            gap: 3px;
        }

        .toolbar-button:active {
            background: #2a2a2a;
        }

        .toolbar-button.recording {
            border-color: #ff3333;
            background: #331111;
        }

        .toolbar-button.playing {
            border-color: #33ff33;
            background: #113311;
        }

        .toolbar-button:disabled {
            opacity: 0.3;
            cursor: not-allowed;
        }

        .button-icon {
            font-size: 24px;
        }

        .button-label {
            font-size: 9px;
        }

        #debug-overlay {
            position: fixed;
            top: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.85);
            color: #0f0;
            padding: 10px;
            border-radius: 6px;
            font-family: monospace;
            font-size: 10px;
            z-index: 200;
            max-width: 200px;
            pointer-events: auto;
            display: none;
        }

        #debug-overlay.active {
            display: block;
        }

        #enable-orientation-btn {
            margin-top: 8px;
            padding: 6px 12px;
            background: #0088ff;
            border: none;
            border-radius: 4px;
            color: white;
            font-size: 11px;
            font-family: -apple-system, sans-serif;
            cursor: pointer;
            display: none;
        }

        #enable-orientation-btn.active {
            display: block;
        }

        .debug-line {
            margin: 2px 0;
        }

        .debug-error {
            color: #f00;
        }

        .debug-success {
            color: #0f0;
        }

        .debug-warning {
            color: #ff0;
        }

        #modal-overlay,
        #permissions-overlay {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.9);
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 2000;
        }

        #modal-overlay.active,
        #permissions-overlay.active {
            display: flex;
        }

        .modal {
            background: #1a1a1a;
            border: 1px solid #444;
            border-radius: 12px;
            padding: 30px;
            max-width: 300px;
            text-align: center;
        }

        .modal-title {
            font-size: 18px;
            margin-bottom: 15px;
        }

        .modal-buttons {
            display: flex;
            gap: 10px;
            margin-top: 20px;
        }

        .modal-button {
            flex: 1;
            padding: 12px;
            border: 1px solid #444;
            background: #2a2a2a;
            color: #e0e0e0;
            border-radius: 6px;
            font-size: 14px;
            cursor: pointer;
        }

        .modal-button.primary {
            background: #ff3333;
            border-color: #ff3333;
        }

        .modal-button:active {
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <div id="app">
        <!-- Debug overlay (commented out for production)
        <div id="debug-overlay" class="active">
            <div class="debug-line">üîç Debug Info</div>
            <div class="debug-line" id="debug-mic">Mic: waiting</div>
            <div class="debug-line" id="debug-orientation">Orient: waiting</div>
            <div class="debug-line" id="debug-layers">Layers: 0/5</div>
            <div class="debug-line" id="debug-rendered">Rendered: 0</div>
            <div class="debug-line" id="debug-spectrogram">Spectro: --</div>
            <div class="debug-line" id="debug-beta">Œ≤: --</div>
            <div class="debug-line" id="debug-gamma">Œ≥: --</div>
            <div class="debug-line" id="debug-alpha">Œ±: --</div>
            <div class="debug-line" id="debug-speed">Speed: 1.0x</div>
            <div class="debug-line" id="debug-reverb">Reverb: 0.0</div>
            <div class="debug-line" id="debug-filter">Filter: none</div>
            <button id="enable-orientation-btn">Enable Tilt Controls</button>
        </div>
        -->

        <div id="layers-container"></div>

        <svg id="playback-indicator" width="300" height="300" viewBox="0 0 300 300">
            <g id="reverb-circles"></g>
            <circle cx="150" cy="150" r="140" fill="none" stroke="rgba(255,255,255,0.1)" stroke-width="2"/>
            <g id="yaw-indicator"></g>
            <circle id="playback-dot" cx="150" cy="10" r="8" fill="#00ffff"/>
        </svg>

        <div id="toolbar">
            <button class="toolbar-button" id="record-btn">
                <div class="button-icon">‚óè</div>
                <div class="button-label">Record</div>
            </button>
            <button class="toolbar-button" id="play-btn" disabled>
                <div class="button-icon">‚ñ∂</div>
                <div class="button-label">Play</div>
            </button>
            <button class="toolbar-button" id="nuke-btn" disabled>
                <div class="button-icon">‚úï</div>
                <div class="button-label">Clear All</div>
            </button>
        </div>
    </div>

    <div id="modal-overlay">
        <div class="modal">
            <div class="modal-title">Clear all layers?</div>
            <div>This will delete all recordings and cannot be undone.</div>
            <div class="modal-buttons">
                <button class="modal-button" id="modal-cancel">Cancel</button>
                <button class="modal-button primary" id="modal-confirm">Clear All</button>
            </div>
        </div>
    </div>

    <div id="permissions-overlay" class="active">
        <button class="modal-button primary" id="request-mic-btn" style="font-size: 16px; padding: 16px 32px;">Enable Microphone</button>
    </div>

    <script>
        // ============================================================================
        // GLOBAL STATE
        // ============================================================================

        const MAX_LAYERS = 5;
        const MAX_RECORDING_TIME = 30000; // 30 seconds
        const SAMPLE_RATE = 44100;
        const FFT_SIZE = 4096;
        const MIN_FREQ = 40;
        const MAX_FREQ = 10000;

        let audioContext;
        let analyser;
        let mediaRecorder;
        let recordingChunks = [];
        let recordingStartTime;
        let recordingTimeout;
        let currentRecordingLayer = null;
        let mediaStream = null;
        let isInitialized = false;
        let shouldAutoReconnect = false; // Track if we should auto-reconnect on visibility change

        let layers = [];
        let isPlaying = false;
        let playbackStartTime = 0;
        let animationFrameId = null;
        let lastVisualPosition = 0;
        let lastPositionUpdateTime = 0;

        let orientationData = {
            speed: 1.0,  // 0.1 to 10
            reverb: 0.0, // 0 to 1
            filterType: 'allpass', // 'lowpass', 'highpass', 'allpass'
            filterFreq: 1000 // Hz
        };

        let convolver;
        let masterGain;

        // Granular synthesis for pitch-preserving time stretch
        const GRAIN_SIZE = 0.05; // 50ms grains
        const GRAIN_OVERLAP = 0.75; // 75% overlap

        // ============================================================================
        // INITIALIZATION
        // ============================================================================

        // Convert linear slider value (0-100) to logarithmic gain (0-1)
        // Human hearing is logarithmic, so this provides better volume control
        function sliderToGain(sliderValue) {
            if (sliderValue === 0) return 0;
            // Exponential curve: 50% slider = -20dB, 75% = -10dB, 100% = 0dB
            return Math.pow(10, ((sliderValue / 100) - 1) * 2);
        }

        // Helper for debug logging (safe if debug overlay is commented out)
        function debugLog(elementId, text, className = null) {
            const el = document.getElementById(elementId);
            if (el) {
                el.textContent = text;
                if (className) el.className = className;
            }
        }

        async function init() {
            try {
                // Initialize audio context (doesn't require user permission)
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE
                });

                // Create master gain with reasonable default (0.3 = -10dB)
                masterGain = audioContext.createGain();
                masterGain.gain.value = 0.3;
                masterGain.connect(audioContext.destination);

                // Create convolver for reverb
                convolver = audioContext.createConvolver();
                convolver.buffer = createReverbImpulse();

                console.log('Sound Catcher UI initialized');
            } catch (error) {
                console.error('Failed to initialize audio:', error);
                alert('Failed to initialize audio system. Please refresh the page.');
            }
        }

        async function requestPermissions() {
            // Permissions are now handled by the overlay on first load
            // This function just ensures init has happened
            if (isInitialized) return true;

            // Ensure audioContext is initialized
            if (!audioContext) {
                await init();
            }

            return isInitialized;
        }

        async function requestOrientationPermission() {
            if (typeof DeviceOrientationEvent === 'undefined') {
                console.log('‚ùå DeviceOrientation not supported');
                debugLog('debug-orientation', 'Orient: not supported');
                debugLog('debug-orientation', null, 'debug-line debug-error');
                return false;
            }

            debugLog('debug-orientation', 'Orient: checking...');
            debugLog('debug-orientation', null, 'debug-line debug-warning');

            console.log('üì± Checking orientation support...');
            console.log('   requestPermission?', typeof DeviceOrientationEvent.requestPermission);

            if (typeof DeviceOrientationEvent.requestPermission === 'function') {
                // iOS 13+ requires explicit permission
                try {
                    console.log('   ‚Üí Requesting iOS orientation permission...');
                    debugLog('debug-orientation', 'Orient: requesting iOS...');

                    const response = await DeviceOrientationEvent.requestPermission();
                    console.log('   ‚úì Response:', response);

                    if (response === 'granted') {
                        window.addEventListener('deviceorientation', handleOrientation, true);
                        console.log('‚úÖ Orientation enabled (iOS)');
                        debugLog('debug-orientation', 'Orient: ‚úì granted (iOS)');
                        debugLog('debug-orientation', null, 'debug-line debug-success');
                        return true;
                    } else {
                        console.log('‚ö†Ô∏è Orientation denied');
                        debugLog('debug-orientation', 'Orient: ‚úó denied');
                        debugLog('debug-orientation', null, 'debug-line debug-error');
                        return false;
                    }
                } catch (error) {
                    console.error('‚ùå Orientation error:', error);
                    const msg = error.message || 'unknown error';
                    debugLog('debug-orientation', `Orient: ${msg.substring(0, 20)}`);
                    debugLog('debug-orientation', null, 'debug-line debug-error');
                    return false;
                }
            } else {
                // Android and older iOS
                window.addEventListener('deviceorientation', handleOrientation, true);
                console.log('‚úÖ Orientation enabled (no permission)');
                debugLog('debug-orientation', 'Orient: ‚úì auto (Android)');
                debugLog('debug-orientation', null, 'debug-line debug-success');
                return true;
            }
        }

        // ============================================================================
        // LAYER MANAGEMENT
        // ============================================================================

        function createLayer(audioBuffer = null) {
            console.log(`createLayer called: current layers=${layers.length}, max=${MAX_LAYERS}, hasAudio=${!!audioBuffer}`);

            if (layers.length >= MAX_LAYERS) {
                console.log(`Blocked: Maximum ${MAX_LAYERS} layers reached`);
                alert(`Maximum ${MAX_LAYERS} layers reached`);
                return null;
            }

            const layerIndex = layers.length;
            const layer = {
                id: Date.now() + layerIndex,
                audioBuffer: audioBuffer,
                volume: sliderToGain(80), // Default to 80% slider position (~0.4 gain)
                selection: { start: 0, end: 1 }, // Normalized 0-1
                sourceNode: null,
                gainNode: null,
                spectrogramData: null
            };

            layers.push(layer);
            console.log(`Layer created with ID ${layer.id}, total layers now: ${layers.length}`);

            renderLayer(layer, layerIndex);
            updateToolbarState();
            adjustLayerHeights(); // Resize all layers to fit
            updateDebugLayerInfo();

            return layer;
        }

        function updateDebugLayerInfo() {
            const numLayers = layers.length;
            const numWithAudio = layers.filter(l => l.audioBuffer).length;
            const numRendered = document.querySelectorAll('.layer').length;

            debugLog('debug-layers', `Layers: ${numLayers}/5 (${numWithAudio} w/audio)`);
            debugLog('debug-rendered', `Rendered: ${numRendered}`);
        }

        function renderLayer(layer, index) {
            // Only render layers that have audio
            if (!layer.audioBuffer) {
                console.log(`renderLayer: skipping layer ${layer.id} (no audio buffer)`);
                return;
            }

            console.log(`renderLayer: rendering layer ${layer.id} at index ${index}`);
            const container = document.getElementById('layers-container');
            const layerDiv = document.createElement('div');
            layerDiv.className = 'layer';
            layerDiv.id = `layer-${layer.id}`;

            // Canvas container
            const canvasContainer = document.createElement('div');
            canvasContainer.className = 'layer-canvas-container';

            const canvas = document.createElement('canvas');
            canvas.width = window.innerWidth - 60;
            canvas.height = 150;
            canvasContainer.appendChild(canvas);

            // Selection overlay
            const selectionOverlay = document.createElement('div');
            selectionOverlay.className = 'selection-overlay';

            if (layer.audioBuffer) {
                const dimLeft = document.createElement('div');
                dimLeft.className = 'selection-dim';
                dimLeft.style.left = '0';
                dimLeft.style.width = '5%';

                const dimRight = document.createElement('div');
                dimRight.className = 'selection-dim';
                dimRight.style.left = '95%';
                dimRight.style.width = '5%';

                // Position handles at edges of spectrogram mesh (5% to 95% width)
                const meshStart = 5;
                const meshEnd = 95;

                const handleStart = document.createElement('div');
                handleStart.className = 'selection-handle';
                handleStart.style.left = `${meshStart}%`;
                handleStart.dataset.handle = 'start';

                const handleEnd = document.createElement('div');
                handleEnd.className = 'selection-handle';
                handleEnd.style.left = `${meshEnd}%`;
                handleEnd.dataset.handle = 'end';

                selectionOverlay.appendChild(dimLeft);
                selectionOverlay.appendChild(dimRight);
                selectionOverlay.appendChild(handleStart);
                selectionOverlay.appendChild(handleEnd);

                setupSelectionHandles(layer, selectionOverlay);

                // Initialize selection UI to match current selection values
                updateSelectionUI(layer, selectionOverlay);
            }

            canvasContainer.appendChild(selectionOverlay);

            // Layer controls
            const controls = document.createElement('div');
            controls.className = 'layer-controls';

            const volumeSlider = document.createElement('input');
            volumeSlider.type = 'range';
            volumeSlider.min = '0';
            volumeSlider.max = '100';
            volumeSlider.value = '80'; // Default to 80% (roughly -6dB)
            volumeSlider.className = 'volume-slider';
            volumeSlider.addEventListener('input', (e) => {
                const sliderValue = parseInt(e.target.value);
                const gain = sliderToGain(sliderValue);
                layer.volume = gain;
                if (layer.gainNode) {
                    layer.gainNode.gain.setValueAtTime(gain, audioContext.currentTime);
                }
            });

            const reRecordBtn = document.createElement('button');
            reRecordBtn.className = 'layer-button';
            reRecordBtn.textContent = '‚Üª';
            reRecordBtn.title = 'Re-record this layer';
            reRecordBtn.addEventListener('click', () => reRecordLayer(layer));

            if (layer.audioBuffer) {
                controls.appendChild(volumeSlider);
                controls.appendChild(reRecordBtn);
            }

            layerDiv.appendChild(canvasContainer);
            layerDiv.appendChild(controls);
            container.appendChild(layerDiv);

            // Draw spectrogram if we have audio
            if (layer.audioBuffer) {
                drawSpectrogram(layer, canvas);
            }

            // Adjust layer heights
            adjustLayerHeights();
        }

        function adjustLayerHeights() {
            const container = document.getElementById('layers-container');
            const containerHeight = window.innerHeight - 80; // Minus toolbar
            const layerDivs = container.querySelectorAll('.layer');

            // Calculate height per layer (only count layers with audio)
            const numLayersWithAudio = layers.filter(l => l.audioBuffer).length;
            if (numLayersWithAudio === 0) return;

            // Lower minimum height to fit 5 layers
            const layerHeight = Math.max(80, Math.floor(containerHeight / numLayersWithAudio));

            layerDivs.forEach((div, idx) => {
                const canvasContainer = div.querySelector('.layer-canvas-container');
                canvasContainer.style.height = `${layerHeight}px`;

                const canvas = div.querySelector('canvas');
                // Update canvas dimensions to match container
                canvas.width = window.innerWidth - 60;
                canvas.height = layerHeight;

                // Redraw if layer has data
                if (layers[idx] && layers[idx].audioBuffer) {
                    drawSpectrogram(layers[idx], canvas);
                }
            });
        }

        function setupSelectionHandles(layer, overlay) {
            const handles = overlay.querySelectorAll('.selection-handle');
            let activeHandle = null;
            let startX = 0;
            let startValue = 0;

            handles.forEach(handle => {
                handle.addEventListener('touchstart', (e) => {
                    e.preventDefault();
                    e.stopPropagation();
                    activeHandle = handle;
                    startX = e.touches[0].clientX;
                    startValue = handle.dataset.handle === 'start' ? layer.selection.start : layer.selection.end;
                    debugLog('debug-spectrogram', `Drag: ${handle.dataset.handle}`);
                    console.log(`Touch start on ${handle.dataset.handle} handle`);
                }, { passive: false });
            });

            let lastUpdateTime = 0;
            const UPDATE_THROTTLE = 100; // ms - throttle playback restarts

            overlay.addEventListener('touchmove', (e) => {
                if (!activeHandle) return;
                e.preventDefault();
                e.stopPropagation();

                const rect = overlay.getBoundingClientRect();
                const currentX = e.touches[0].clientX;

                // Calculate position relative to mesh area (5% to 95%)
                const meshStart = 0.05;
                const meshWidth = 0.9;
                const relativeX = (currentX - rect.left) / rect.width;
                const meshRelativeX = (relativeX - meshStart) / meshWidth;
                const clampedValue = Math.max(0, Math.min(1, meshRelativeX));

                if (activeHandle.dataset.handle === 'start') {
                    layer.selection.start = Math.min(clampedValue, layer.selection.end - 0.01);
                    debugLog('debug-spectrogram', `Start: ${layer.selection.start.toFixed(2)}`);
                } else {
                    layer.selection.end = Math.max(clampedValue, layer.selection.start + 0.01);
                    debugLog('debug-spectrogram', `End: ${layer.selection.end.toFixed(2)}`);
                }

                updateSelectionUI(layer, overlay);

                // Note: Selection changes are automatically picked up by the granular scheduler
                // which reads layer.selection on each grain, so no manual restart needed
            }, { passive: false });

            overlay.addEventListener('touchend', (e) => {
                if (activeHandle) {
                    e.preventDefault();
                    e.stopPropagation();
                    activeHandle = null;
                    // Selection changes are picked up automatically by granular scheduler
                }
            }, { passive: false });
        }

        function updateSelectionUI(layer, overlay) {
            const dimLeft = overlay.querySelector('.selection-dim:first-child');
            const dimRight = overlay.querySelector('.selection-dim:last-child');
            const handleStart = overlay.querySelector('[data-handle="start"]');
            const handleEnd = overlay.querySelector('[data-handle="end"]');

            if (!handleStart || !handleEnd) {
                console.error('Selection handles not found in overlay!');
                return;
            }

            // Map selection (0-1) to mesh range (5%-95%)
            const meshStart = 5;
            const meshWidth = 90; // 95% - 5%
            const startPercent = meshStart + (layer.selection.start * meshWidth);
            const endPercent = meshStart + (layer.selection.end * meshWidth);

            // Update dim overlays (if they exist)
            if (dimLeft) {
                dimLeft.style.left = '0';
                dimLeft.style.width = `${startPercent}%`;
            }

            if (dimRight) {
                dimRight.style.left = `${endPercent}%`;
                dimRight.style.width = `${100 - endPercent}%`;
            }

            // Update handles
            handleStart.style.left = `${startPercent}%`;
            handleEnd.style.left = `${endPercent}%`;

            console.log(`Updated handles: start=${startPercent.toFixed(1)}%, end=${endPercent.toFixed(1)}%`);
        }

        function reRecordLayer(layer) {
            if (isPlaying) {
                stopPlayback();
            }

            currentRecordingLayer = layer;
            startRecording();
        }

        function nukeAllLayers() {
            document.getElementById('modal-overlay').classList.add('active');
        }

        // ============================================================================
        // RECORDING
        // ============================================================================

        async function startRecording() {
            // Permissions are handled by the overlay now
            try {
                recordingChunks = [];
                recordingStartTime = Date.now();
                mediaRecorder.start();

                const recordBtn = document.getElementById('record-btn');
                recordBtn.classList.add('recording');
                recordBtn.querySelector('.button-label').textContent = 'Recording...';

                // Auto-stop after 30 seconds
                recordingTimeout = setTimeout(() => {
                    if (mediaRecorder.state === 'recording') {
                        stopRecording();
                    }
                }, MAX_RECORDING_TIME);

                console.log('Recording started');
            } catch (error) {
                console.error('Recording failed:', error);
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                clearTimeout(recordingTimeout);
                mediaRecorder.stop();

                const recordBtn = document.getElementById('record-btn');
                recordBtn.classList.remove('recording');
                recordBtn.querySelector('.button-label').textContent = 'Record';

                console.log('Recording stopped');
            }
        }

        async function handleRecordingComplete() {
            try {
                if (!audioContext) {
                    throw new Error('Audio context not initialized');
                }

                const blob = new Blob(recordingChunks, { type: 'audio/webm' });
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                if (currentRecordingLayer) {
                    // Re-recording existing layer
                    currentRecordingLayer.audioBuffer = audioBuffer;
                    currentRecordingLayer.selection = { start: 0, end: 1 };

                    // Re-render this layer
                    const layerDiv = document.getElementById(`layer-${currentRecordingLayer.id}`);
                    layerDiv.remove();
                    const layerIndex = layers.indexOf(currentRecordingLayer);
                    renderLayer(currentRecordingLayer, layerIndex);

                    currentRecordingLayer = null;
                } else {
                    // Add new layer with audio
                    createLayer(audioBuffer);

                    // Auto-start or restart playback to include new layer
                    if (isPlaying) {
                        stopPlayback();
                        startPlayback();
                    } else {
                        startPlayback();
                    }
                }

                updateToolbarState();
                updateDebugLayerInfo();
                console.log('Recording processed successfully');
            } catch (error) {
                console.error('Failed to process recording:', error);
                alert(`Recording failed: ${error.message}`);
            }
        }

        // ============================================================================
        // SPECTROGRAM GENERATION (3D PERSPECTIVE MESH)
        // ============================================================================

        async function drawSpectrogram(layer, canvas) {
            const ctx = canvas.getContext('2d');
            const width = canvas.width;
            const height = canvas.height;

            // Clear canvas
            ctx.fillStyle = '#0a0a0a';
            ctx.fillRect(0, 0, width, height);

            if (!layer.audioBuffer) {
                console.log('Cannot draw spectrogram: no audio buffer');
                debugLog('debug-spectrogram', 'Spectro: no buffer');
                return;
            }

            debugLog('debug-spectrogram', `Spectro: drawing ${width}x${height}`);
            console.log(`Drawing spectrogram: ${width}x${height}, duration: ${layer.audioBuffer.duration}s`);

            // Calculate frequency range bins
            const nyquist = layer.audioBuffer.sampleRate / 2;
            const bufferLength = FFT_SIZE / 2;
            const minBin = Math.floor((MIN_FREQ / nyquist) * bufferLength);
            const maxBin = Math.ceil((MAX_FREQ / nyquist) * bufferLength);
            const freqBins = 64; // Fixed vertical resolution for 3D mesh

            // Time resolution
            const duration = layer.audioBuffer.duration;
            const timeSteps = 128; // Fixed horizontal resolution
            const stepSize = duration / timeSteps;

            // Store spectrogram data
            const spectrogramData = [];

            // Analyze audio in chunks
            const channelData = layer.audioBuffer.getChannelData(0);

            for (let t = 0; t < timeSteps; t++) {
                const sampleOffset = Math.floor((t * stepSize) * layer.audioBuffer.sampleRate);
                const chunk = channelData.slice(sampleOffset, sampleOffset + FFT_SIZE);

                if (chunk.length < FFT_SIZE) break;

                // Simple FFT simulation (in production, use actual FFT library)
                const freqData = performSimpleFFT(chunk, freqBins, minBin, maxBin, bufferLength);
                spectrogramData.push(freqData);
            }

            layer.spectrogramData = spectrogramData;

            // Draw 3D mesh
            draw3DSpectrogram(ctx, spectrogramData, width, height);

            // Apply darkening overlay to push spectrogram into background
            ctx.fillStyle = 'rgba(10, 10, 10, 0.7)'; // Dark semi-transparent overlay
            ctx.fillRect(0, 0, width, height);

            // Draw amplitude waveform on top
            drawAmplitudeWaveform(ctx, layer.audioBuffer, width, height);

            debugLog('debug-spectrogram', `Spectro: ‚úì ${timeSteps}x${freqBins}`);
        }

        function draw3DSpectrogram(ctx, data, width, height) {
            if (!data || data.length === 0) return;

            const timeSteps = data.length;
            const freqBins = data[0].length;

            // 3D perspective parameters
            const perspective = 600; // Perspective strength
            const angleX = -30; // Tilt away from viewer (negative = top recedes)
            const scale = 0.85; // Scaled down to fit with tilt
            const amplitudeScale = 50; // How far amplitude extends in Z

            // Calculate center point (centered to fit within bounds)
            const centerX = width / 2;
            const centerY = height * 0.5; // Centered vertically

            // Pre-calculate rotation (X-axis tilt away from viewer)
            const radX = (angleX * Math.PI) / 180;
            const cosX = Math.cos(radX);
            const sinX = Math.sin(radX);

            // Project 3D point to 2D with perspective
            // x = time (horizontal), y = frequency (vertical), z = amplitude (depth)
            function project3D(x, y, z) {
                // Apply X-axis rotation (tilt back - top away, bottom closer)
                const rotatedY = y * cosX - z * sinX;
                const rotatedZ = y * sinX + z * cosX;

                // Apply perspective
                const factor = perspective / (perspective + rotatedZ);
                const screenX = centerX + x * factor * scale;
                const screenY = centerY + rotatedY * factor * scale;

                return { x: screenX, y: screenY, z: rotatedZ };
            }

            // Mesh dimensions (5% to 95% = 90% width)
            const meshWidth = width * 0.9;
            const meshHeight = height * 0.7; // Taller mesh for better visualization

            // Draw mesh from back to front for proper occlusion
            for (let f = freqBins - 1; f >= 0; f--) {
                for (let t = 0; t < timeSteps - 1; t++) {
                    // Get magnitude values at 4 corners of quad
                    const mag00 = data[t][f] || 0;
                    const mag10 = data[t + 1][f] || 0;
                    const mag01 = f > 0 ? (data[t][f - 1] || 0) : 0;
                    const mag11 = f > 0 ? (data[t + 1][f - 1] || 0) : 0;

                    // Calculate 3D positions
                    // X = time (left to right)
                    const x0 = (t / timeSteps) * meshWidth - meshWidth / 2;
                    const x1 = ((t + 1) / timeSteps) * meshWidth - meshWidth / 2;

                    // Y = frequency (bottom to top)
                    const y0 = (f / freqBins) * meshHeight - meshHeight / 2;
                    const y1 = ((f - 1) / freqBins) * meshHeight - meshHeight / 2;

                    // Z = amplitude (depth toward viewer)
                    const z00 = mag00 * amplitudeScale;
                    const z10 = mag10 * amplitudeScale;
                    const z01 = mag01 * amplitudeScale;
                    const z11 = mag11 * amplitudeScale;

                    // Project to 2D
                    const p00 = project3D(x0, y0, z00);
                    const p10 = project3D(x1, y0, z10);
                    const p01 = project3D(x0, y1, z01);
                    const p11 = project3D(x1, y1, z11);

                    // Color based on average magnitude
                    const avgMag = (mag00 + mag10 + mag01 + mag11) / 4;
                    const color = getHeatmapColor(avgMag);

                    // Depth-based brightness
                    const avgZ = (p00.z + p10.z + p01.z + p11.z) / 4;
                    const brightness = 0.4 + (avgZ / (perspective * 0.5)) * 0.6;

                    ctx.fillStyle = `rgb(${color.r * brightness}, ${color.g * brightness}, ${color.b * brightness})`;
                    ctx.strokeStyle = 'rgba(0, 0, 0, 0.2)';
                    ctx.lineWidth = 0.5;

                    // Draw quad as two triangles
                    ctx.beginPath();
                    ctx.moveTo(p00.x, p00.y);
                    ctx.lineTo(p10.x, p10.y);
                    ctx.lineTo(p11.x, p11.y);
                    ctx.closePath();
                    ctx.fill();
                    ctx.stroke();

                    if (f > 0) {
                        ctx.beginPath();
                        ctx.moveTo(p00.x, p00.y);
                        ctx.lineTo(p11.x, p11.y);
                        ctx.lineTo(p01.x, p01.y);
                        ctx.closePath();
                        ctx.fill();
                        ctx.stroke();
                    }
                }
            }
        }

        function drawAmplitudeWaveform(ctx, audioBuffer, width, height) {
            if (!audioBuffer) return;

            // Match spectrogram mesh bounds (5% to 95% of width)
            const meshStartPercent = 0.05;
            const meshEndPercent = 0.95;
            const meshWidth = width * (meshEndPercent - meshStartPercent);
            const meshStartX = width * meshStartPercent;

            // Get audio data
            const channelData = audioBuffer.getChannelData(0);
            const sampleCount = channelData.length;
            const samplesPerPixel = Math.floor(sampleCount / meshWidth);

            // Calculate downsampled envelope
            const amplitudes = [];
            for (let x = 0; x < meshWidth; x++) {
                const startSample = x * samplesPerPixel;
                const endSample = Math.min(startSample + samplesPerPixel, sampleCount);

                // Find peak amplitude in this window
                let max = 0;
                for (let i = startSample; i < endSample; i++) {
                    max = Math.max(max, Math.abs(channelData[i]));
                }
                amplitudes.push(max);
            }

            // Draw waveform
            const centerY = height / 2;
            const amplitudeScale = height * 0.35; // Use 35% of height for amplitude range

            ctx.strokeStyle = 'rgba(0, 255, 255, 0.9)'; // Cyan with high opacity
            ctx.lineWidth = 1.5;
            ctx.beginPath();

            // Draw top envelope (offset by meshStartX)
            for (let x = 0; x < amplitudes.length; x++) {
                const screenX = meshStartX + x;
                const y = centerY - (amplitudes[x] * amplitudeScale);
                if (x === 0) {
                    ctx.moveTo(screenX, y);
                } else {
                    ctx.lineTo(screenX, y);
                }
            }

            // Draw bottom envelope (mirror, offset by meshStartX)
            for (let x = amplitudes.length - 1; x >= 0; x--) {
                const screenX = meshStartX + x;
                const y = centerY + (amplitudes[x] * amplitudeScale);
                ctx.lineTo(screenX, y);
            }

            ctx.closePath();
            ctx.fillStyle = 'rgba(0, 255, 255, 0.15)'; // Light cyan fill
            ctx.fill();
            ctx.stroke();

            // Draw center line (only in mesh area)
            ctx.strokeStyle = 'rgba(0, 255, 255, 0.3)';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(meshStartX, centerY);
            ctx.lineTo(meshStartX + meshWidth, centerY);
            ctx.stroke();
        }

        function performSimpleFFT(samples, outputSize, minBin, maxBin, bufferLength) {
            // Simplified magnitude calculation with frequency range support
            // In production, use an actual FFT library like fft.js
            const magnitudes = new Array(outputSize).fill(0);

            for (let i = 0; i < outputSize; i++) {
                // Map output bin to input frequency range
                const freqBin = minBin + (i / outputSize) * (maxBin - minBin);
                const binStart = Math.floor((freqBin / bufferLength) * samples.length);
                const binEnd = Math.floor(((freqBin + 1) / bufferLength) * samples.length);

                let sum = 0;
                let count = 0;
                for (let j = binStart; j < Math.min(binEnd, samples.length); j++) {
                    sum += Math.abs(samples[j]);
                    count++;
                }
                magnitudes[i] = count > 0 ? sum / count : 0;
            }

            // Normalize
            const max = Math.max(...magnitudes);
            return magnitudes.map(m => m / (max || 1));
        }

        function getHeatmapColor(value) {
            // Blue -> Yellow -> Red
            // 0.0 = Blue (0, 0, 255)
            // 0.5 = Yellow (255, 255, 0)
            // 1.0 = Red (255, 0, 0)

            if (value < 0.5) {
                const t = value * 2;
                return {
                    r: Math.floor(t * 255),
                    g: Math.floor(t * 255),
                    b: Math.floor((1 - t) * 255)
                };
            } else {
                const t = (value - 0.5) * 2;
                return {
                    r: 255,
                    g: Math.floor((1 - t) * 255),
                    b: 0
                };
            }
        }

        // ============================================================================
        // PLAYBACK
        // ============================================================================

        function togglePlayback() {
            if (isPlaying) {
                stopPlayback();
            } else {
                startPlayback();
            }
        }

        function startPlayback() {
            if (audioContext.state === 'suspended') {
                audioContext.resume();
            }

            isPlaying = true;
            playbackStartTime = audioContext.currentTime;

            // Find longest selection duration
            const maxDuration = getMaxSelectionDuration();

            if (maxDuration === 0) return;

            // Start all layers
            layers.forEach(layer => {
                if (layer.audioBuffer) {
                    scheduleLayerPlayback(layer, maxDuration);
                }
            });

            // Update UI
            const playBtn = document.getElementById('play-btn');
            playBtn.classList.add('playing');
            playBtn.querySelector('.button-icon').textContent = '‚è∏';
            playBtn.querySelector('.button-label').textContent = 'Pause';

            document.getElementById('playback-indicator').classList.add('active');

            // Start animation loop
            animatePlayback();

            console.log('Playback started');
        }

        function stopPlayback() {
            isPlaying = false;

            // Reset visual position tracking
            lastVisualPosition = 0;
            lastPositionUpdateTime = 0;

            // Stop all grain scheduling and disconnect nodes
            layers.forEach(layer => {
                if (layer.grainScheduleId) {
                    clearTimeout(layer.grainScheduleId);
                    layer.grainScheduleId = null;
                }
                if (layer.gainNode) {
                    layer.gainNode.disconnect();
                    layer.gainNode = null;
                }
                if (layer.filterNode) {
                    layer.filterNode.disconnect();
                    layer.filterNode = null;
                }
                if (layer.dryGain) {
                    layer.dryGain.disconnect();
                    layer.dryGain = null;
                }
                if (layer.wetGain) {
                    layer.wetGain.disconnect();
                    layer.wetGain = null;
                }
            });

            // Update UI
            const playBtn = document.getElementById('play-btn');
            playBtn.classList.remove('playing');
            playBtn.querySelector('.button-icon').textContent = '‚ñ∂';
            playBtn.querySelector('.button-label').textContent = 'Play';

            document.getElementById('playback-indicator').classList.remove('active');

            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }

            console.log('Playback stopped');
        }

        function scheduleLayerPlayback(layer, loopDuration) {
            // Create gain nodes for this layer
            const layerGain = audioContext.createGain();
            layerGain.gain.value = layer.volume;

            // Create filter node
            const filterNode = audioContext.createBiquadFilter();
            filterNode.type = orientationData.filterType;
            filterNode.frequency.value = orientationData.filterFreq;
            filterNode.Q.value = 1.0; // Standard Q value

            // Apply reverb with dry/wet mix
            const dryGain = audioContext.createGain();
            const wetGain = audioContext.createGain();

            dryGain.gain.value = 1 - orientationData.reverb;
            wetGain.gain.value = orientationData.reverb;

            // Audio routing: layer gain -> filter -> dry/wet split -> master
            layerGain.connect(filterNode);
            filterNode.connect(dryGain);
            filterNode.connect(convolver);
            convolver.connect(wetGain);

            dryGain.connect(masterGain);
            wetGain.connect(masterGain);

            // Store nodes and playback state
            layer.gainNode = layerGain;
            layer.filterNode = filterNode;
            layer.dryGain = dryGain;
            layer.wetGain = wetGain;
            layer.playbackPosition = 0; // Position in seconds within selection
            layer.nextGrainTime = audioContext.currentTime;
            layer.grainScheduleId = null;

            // Start granular playback (reads selection dynamically)
            scheduleGrains(layer);
        }

        function scheduleGrains(layer) {
            if (!isPlaying || !layer.gainNode) return;

            const now = audioContext.currentTime;

            // Read selection dynamically (allows live updates during playback)
            const selectionStart = layer.selection.start * layer.audioBuffer.duration;
            const selectionEnd = layer.selection.end * layer.audioBuffer.duration;
            const selectionDuration = selectionEnd - selectionStart;

            // Schedule grains ahead of time
            while (layer.nextGrainTime < now + 0.2) { // Schedule 200ms ahead
                createGrain(layer, selectionStart, selectionEnd, layer.nextGrainTime);

                // Calculate spacing based on speed (pitch-preserving)
                const grainSpacing = GRAIN_SIZE * (1 - GRAIN_OVERLAP) / orientationData.speed;
                layer.nextGrainTime += grainSpacing;

                // Advance playback position by grain spacing (not grain size!)
                // This is how much audio time we consume per grain
                layer.playbackPosition += (GRAIN_SIZE * (1 - GRAIN_OVERLAP)) / selectionDuration;

                // Loop back to start
                if (layer.playbackPosition >= 1) {
                    layer.playbackPosition = layer.playbackPosition % 1;
                }
            }

            // Continue scheduling (will re-read selection next time)
            layer.grainScheduleId = setTimeout(() => scheduleGrains(layer), 50);
        }

        function createGrain(layer, selectionStart, selectionEnd, startTime) {
            const selectionDuration = selectionEnd - selectionStart;
            const offset = selectionStart + (layer.playbackPosition * selectionDuration);

            // Create grain source
            const grain = audioContext.createBufferSource();
            grain.buffer = layer.audioBuffer;

            // Envelope for smooth grain (no clicks)
            const grainEnv = audioContext.createGain();
            grainEnv.gain.setValueAtTime(0, startTime);
            grainEnv.gain.linearRampToValueAtTime(0.7, startTime + 0.005);
            grainEnv.gain.setValueAtTime(0.7, startTime + GRAIN_SIZE - 0.005);
            grainEnv.gain.linearRampToValueAtTime(0, startTime + GRAIN_SIZE);

            grain.connect(grainEnv);
            grainEnv.connect(layer.gainNode);

            // Play grain at fixed pitch
            try {
                grain.start(startTime, offset, GRAIN_SIZE);
            } catch (e) {
                // Ignore scheduling errors
            }
        }

        function getMaxSelectionDuration() {
            let maxDuration = 0;
            layers.forEach(layer => {
                if (layer.audioBuffer) {
                    const selectionDuration =
                        (layer.selection.end - layer.selection.start) * layer.audioBuffer.duration;
                    maxDuration = Math.max(maxDuration, selectionDuration);
                }
            });
            return maxDuration;
        }

        function animatePlayback() {
            if (!isPlaying) return;

            // Get actual playback position from layers
            let totalPosition = 0;
            let layerCount = 0;
            layers.forEach(layer => {
                if (layer.audioBuffer && layer.playbackPosition !== undefined) {
                    totalPosition += layer.playbackPosition;
                    layerCount++;
                }
            });

            const targetPosition = layerCount > 0 ? totalPosition / layerCount : 0;
            const now = performance.now();

            // Smooth interpolation between position updates
            // Calculate expected progress based on current speed
            if (lastPositionUpdateTime > 0) {
                const deltaTime = (now - lastPositionUpdateTime) / 1000; // seconds
                const maxDuration = getMaxSelectionDuration();

                if (maxDuration > 0) {
                    // How much we should have progressed based on speed
                    const expectedDelta = (deltaTime * orientationData.speed) / maxDuration;

                    // Interpolate smoothly toward target position
                    lastVisualPosition += expectedDelta;

                    // Handle loop wraparound
                    if (lastVisualPosition >= 1) {
                        lastVisualPosition = lastVisualPosition % 1;
                    }

                    // Gently pull toward actual position to avoid drift
                    const drift = targetPosition - lastVisualPosition;
                    // Handle wraparound in drift calculation
                    let adjustedDrift = drift;
                    if (Math.abs(drift) > 0.5) {
                        adjustedDrift = drift > 0 ? drift - 1 : drift + 1;
                    }
                    lastVisualPosition += adjustedDrift * 0.1; // 10% correction per frame

                    if (lastVisualPosition < 0) lastVisualPosition += 1;
                    if (lastVisualPosition >= 1) lastVisualPosition -= 1;
                }
            } else {
                lastVisualPosition = targetPosition;
            }

            lastPositionUpdateTime = now;

            updatePlaybackIndicator(lastVisualPosition);

            animationFrameId = requestAnimationFrame(animatePlayback);
        }

        function updatePlaybackIndicator(progress) {
            const angle = progress * 360 - 90; // Start at top (0 = top of circle)
            const radians = (angle * Math.PI) / 180;
            const x = 150 + 140 * Math.cos(radians);
            const y = 150 + 140 * Math.sin(radians);

            const dot = document.getElementById('playback-dot');
            dot.setAttribute('cx', x);
            dot.setAttribute('cy', y);

            // Update reverb circles
            const reverbCircles = document.getElementById('reverb-circles');
            reverbCircles.innerHTML = '';

            const numCircles = Math.floor(orientationData.reverb * 10);
            for (let i = 0; i < numCircles; i++) {
                const radius = 130 - (i * 10);
                const circle = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                circle.setAttribute('cx', '150');
                circle.setAttribute('cy', '150');
                circle.setAttribute('r', radius);
                circle.setAttribute('fill', 'none');
                circle.setAttribute('stroke', 'rgba(0, 255, 255, 0.2)');
                circle.setAttribute('stroke-width', '1');
                reverbCircles.appendChild(circle);
            }
        }

        function updateYawIndicator(yaw) {
            const yawGroup = document.getElementById('yaw-indicator');
            if (!yawGroup) return;

            // Clear previous indicator
            yawGroup.innerHTML = '';

            const FILTER_DEAD_ZONE = 10;

            // Only show if outside dead zone
            if (Math.abs(yaw) <= FILTER_DEAD_ZONE) return;

            const centerX = 150;
            const centerY = 150;
            const radius = 145;

            // Convert yaw to SVG coordinates
            // 0¬∞ = top (12 o'clock), positive = clockwise
            const startAngle = -90; // Top of circle in SVG coords
            const endAngle = startAngle + yaw;

            // Calculate arc path
            const startRad = (startAngle * Math.PI) / 180;
            const endRad = (endAngle * Math.PI) / 180;

            const startX = centerX + radius * Math.cos(startRad);
            const startY = centerY + radius * Math.sin(startRad);
            const endX = centerX + radius * Math.cos(endRad);
            const endY = centerY + radius * Math.sin(endRad);

            // Determine if we should use large arc flag
            const largeArcFlag = Math.abs(yaw) > 180 ? 1 : 0;
            const sweepFlag = yaw > 0 ? 1 : 0;

            // Create arc path
            const arcPath = document.createElementNS('http://www.w3.org/2000/svg', 'path');
            const pathData = `M ${startX} ${startY} A ${radius} ${radius} 0 ${largeArcFlag} ${sweepFlag} ${endX} ${endY}`;
            arcPath.setAttribute('d', pathData);
            arcPath.setAttribute('fill', 'none');
            arcPath.setAttribute('stroke', 'rgba(255, 51, 51, 0.6)');
            arcPath.setAttribute('stroke-width', '4');
            arcPath.setAttribute('stroke-linecap', 'round');
            yawGroup.appendChild(arcPath);

            // Create arrow at end position
            const arrowSize = 12;
            const arrowAngle = endAngle * Math.PI / 180;

            // Arrow points radially outward
            const arrowTipX = centerX + (radius + 8) * Math.cos(arrowAngle);
            const arrowTipY = centerY + (radius + 8) * Math.sin(arrowAngle);

            // Calculate perpendicular points for arrow base
            const perpAngle1 = arrowAngle + (2.5 * Math.PI / 180);
            const perpAngle2 = arrowAngle - (2.5 * Math.PI / 180);

            const baseX1 = centerX + (radius - 4) * Math.cos(perpAngle1);
            const baseY1 = centerY + (radius - 4) * Math.sin(perpAngle1);
            const baseX2 = centerX + (radius - 4) * Math.cos(perpAngle2);
            const baseY2 = centerY + (radius - 4) * Math.sin(perpAngle2);

            const arrow = document.createElementNS('http://www.w3.org/2000/svg', 'polygon');
            arrow.setAttribute('points', `${arrowTipX},${arrowTipY} ${baseX1},${baseY1} ${baseX2},${baseY2}`);
            arrow.setAttribute('fill', '#ff3333');
            yawGroup.appendChild(arrow);
        }

        function updateCircleTilt(gamma) {
            const indicator = document.getElementById('playback-indicator');
            if (!indicator) return;

            // Apply 3D perspective tilt based on device roll (gamma)
            // rotateY = rotates around Y-axis (vertical axis, top to bottom)
            // Combine with existing translate transform
            indicator.style.transform = `translate(-50%, -50%) perspective(600px) rotateY(${gamma}deg)`;
        }

        // ============================================================================
        // DEVICE ORIENTATION
        // ============================================================================

        let lastOrientationLog = 0;
        const ORIENTATION_LOG_INTERVAL = 1000; // Log every 1 second

        function handleOrientation(event) {
            const beta = event.beta || 0;   // Pitch: -180 to 180
            const gamma = event.gamma || 0; // Roll: -90 to 90
            const alpha = event.alpha || 0; // Yaw: 0 to 360

            // Speed control (pitch) - full range mapping
            // Face up (beta ~0) = 1x
            // Tilted forward (beta -> 180) = 20x
            // Tilted back (beta -> -180) = 0.05x (1/20th)
            const DEAD_ZONE = 5;
            let speed = 1.0;

            if (beta > DEAD_ZONE) {
                // Forward tilt: 0 to 180 degrees maps to 1x to 20x
                const normalizedBeta = Math.min(beta, 180) / 180;
                speed = 1 + normalizedBeta * 19;
            } else if (beta < -DEAD_ZONE) {
                // Backward tilt: 0 to -180 degrees maps to 1x to 0.05x
                const normalizedBeta = Math.max(beta, -180) / 180; // -1 to 0
                speed = Math.max(0.05, 1 + normalizedBeta * 0.95);
            }

            orientationData.speed = speed;

            // Reverb control (roll)
            // Centered (gamma ~0) = 0 reverb
            // Tilted right (gamma -> 90) = max reverb
            let reverb = 0;

            if (Math.abs(gamma) > DEAD_ZONE) {
                reverb = Math.min(Math.abs(gamma) / 90, 1);
            }

            orientationData.reverb = reverb;

            // Filter control (yaw)
            // Convert alpha to -180 to 180 range and reverse so arrow matches phone direction
            let yaw = alpha;
            if (yaw > 180) yaw -= 360;
            yaw = -yaw; // Reverse so positive yaw = phone pointing right

            const FILTER_DEAD_ZONE = 10;
            let filterType = 'allpass';
            let filterFreq = 1000;

            if (yaw < -FILTER_DEAD_ZONE) {
                // Yaw left: Low-pass filter
                // -10¬∞ to -180¬∞ maps to 10kHz to 40Hz
                filterType = 'lowpass';
                const t = (Math.abs(yaw) - FILTER_DEAD_ZONE) / (180 - FILTER_DEAD_ZONE); // 0 to 1
                filterFreq = 10000 * Math.pow(0.004, t); // Exponential: 10kHz -> 40Hz
            } else if (yaw > FILTER_DEAD_ZONE) {
                // Yaw right: High-pass filter
                // +10¬∞ to +180¬∞ maps to 40Hz to 10kHz
                filterType = 'highpass';
                const t = (yaw - FILTER_DEAD_ZONE) / (180 - FILTER_DEAD_ZONE); // 0 to 1
                filterFreq = 40 * Math.pow(250, t); // Exponential: 40Hz -> 10kHz
            }

            orientationData.filterType = filterType;
            orientationData.filterFreq = filterFreq;

            // Update debug display
            debugLog('debug-beta', `Œ≤: ${beta.toFixed(1)}¬∞`);
            debugLog('debug-gamma', `Œ≥: ${gamma.toFixed(1)}¬∞`);
            debugLog('debug-alpha', `Œ±: ${yaw.toFixed(1)}¬∞`);
            debugLog('debug-speed', `Speed: ${speed.toFixed(2)}x`);
            debugLog('debug-reverb', `Reverb: ${reverb.toFixed(2)}`);

            const filterDisplay = filterType === 'allpass'
                ? 'none'
                : `${filterType} ${filterFreq.toFixed(0)}Hz`;
            debugLog('debug-filter', `Filter: ${filterDisplay}`);

            // Debug logging (throttled)
            const now = Date.now();
            if (now - lastOrientationLog > ORIENTATION_LOG_INTERVAL) {
                console.log(`Orientation: Œ≤=${beta.toFixed(1)}¬∞ Œ≥=${gamma.toFixed(1)}¬∞ Œ±=${yaw.toFixed(1)}¬∞ ‚Üí speed=${speed.toFixed(2)}x reverb=${reverb.toFixed(2)} filter=${filterType}@${filterFreq.toFixed(0)}Hz`);
                lastOrientationLog = now;
            }

            // Update yaw indicator visualization
            updateYawIndicator(yaw);

            // Update circle tilt to match device roll
            updateCircleTilt(gamma);

            // Update active playback
            if (isPlaying) {
                updatePlaybackParameters();
            }
        }

        function updatePlaybackParameters() {
            // Update reverb dry/wet mix and filter in real-time
            // Speed is handled automatically by grain scheduling
            layers.forEach(layer => {
                if (layer.dryGain) {
                    layer.dryGain.gain.setValueAtTime(
                        1 - orientationData.reverb,
                        audioContext.currentTime
                    );
                }
                if (layer.wetGain) {
                    layer.wetGain.gain.setValueAtTime(
                        orientationData.reverb,
                        audioContext.currentTime
                    );
                }
                if (layer.filterNode) {
                    layer.filterNode.type = orientationData.filterType;
                    layer.filterNode.frequency.setValueAtTime(
                        orientationData.filterFreq,
                        audioContext.currentTime
                    );
                }
            });
        }

        // ============================================================================
        // REVERB IMPULSE GENERATION
        // ============================================================================

        function createReverbImpulse() {
            const sampleRate = audioContext.sampleRate;
            const length = sampleRate * 2; // 2 second reverb
            const impulse = audioContext.createBuffer(2, length, sampleRate);
            const left = impulse.getChannelData(0);
            const right = impulse.getChannelData(1);

            for (let i = 0; i < length; i++) {
                const decay = Math.exp(-i / (sampleRate * 0.5));
                left[i] = (Math.random() * 2 - 1) * decay;
                right[i] = (Math.random() * 2 - 1) * decay;
            }

            return impulse;
        }

        // ============================================================================
        // UI HANDLERS
        // ============================================================================

        function updateToolbarState() {
            const hasAudio = layers.some(l => l.audioBuffer !== null);

            document.getElementById('play-btn').disabled = !hasAudio;
            document.getElementById('nuke-btn').disabled = !hasAudio;
        }

        // Helper function to setup microphone
        async function setupMicrophone() {
            try {
                // Ensure audioContext is initialized first
                if (!audioContext) {
                    await init();
                }

                // Request microphone
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaStream = stream;

                // Setup media recorder
                mediaRecorder = new MediaRecorder(mediaStream);
                mediaRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) {
                        recordingChunks.push(e.data);
                    }
                };
                mediaRecorder.onstop = handleRecordingComplete;

                // Mark that we should auto-reconnect on visibility changes
                shouldAutoReconnect = true;

                console.log('Microphone setup complete');
                return true;
            } catch (error) {
                console.error('Microphone setup error:', error);
                shouldAutoReconnect = false;
                return false;
            }
        }

        // Permission overlay handlers
        document.getElementById('request-mic-btn').addEventListener('click', async () => {
            const success = await setupMicrophone();

            if (success) {
                // Update button for orientation request
                document.getElementById('request-mic-btn').textContent = 'Enable Tilt';
                document.getElementById('request-mic-btn').id = 'request-orientation-btn';

                // Orientation button handler
                document.getElementById('request-orientation-btn').addEventListener('click', async () => {
                    const granted = await requestOrientationPermission();
                    document.getElementById('permissions-overlay').classList.remove('active');
                    isInitialized = true;

                    if (!granted) {
                        setTimeout(() => {
                            alert('Tilt controls could not be enabled. You can still use the looper normally.');
                        }, 300);
                    }
                });
            }
        });

        // Event Listeners
        document.getElementById('record-btn').addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            } else {
                // Check if initialized
                if (!isInitialized || !mediaRecorder) {
                    alert('Please complete the permission setup first.');
                    return;
                }
                currentRecordingLayer = null;
                startRecording();
            }
        });

        document.getElementById('play-btn').addEventListener('click', togglePlayback);

        document.getElementById('nuke-btn').addEventListener('click', nukeAllLayers);

        document.getElementById('modal-cancel').addEventListener('click', () => {
            document.getElementById('modal-overlay').classList.remove('active');
        });

        document.getElementById('modal-confirm').addEventListener('click', () => {
            stopPlayback();

            // Clear all layers
            const container = document.getElementById('layers-container');
            container.innerHTML = '';
            layers = [];

            // Don't create empty layer - recording will create layers as needed
            document.getElementById('modal-overlay').classList.remove('active');
            updateToolbarState();
            updateDebugLayerInfo();
        });

        // Window resize handler
        window.addEventListener('resize', () => {
            adjustLayerHeights();
        });

        // Enable orientation button handler
        document.getElementById('enable-orientation-btn').addEventListener('click', async () => {
            await requestOrientationPermission();
        });

        // ============================================================================
        // PAGE VISIBILITY - Stop microphone when app is in background
        // ============================================================================

        document.addEventListener('visibilitychange', async () => {
            if (document.hidden) {
                console.log('Page hidden - stopping microphone access');

                // Stop any active recording
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    console.log('Stopping active recording due to page hide');
                    stopRecording();
                }

                // Stop media stream to release microphone
                if (mediaStream) {
                    console.log('Stopping media stream tracks');
                    mediaStream.getTracks().forEach(track => {
                        track.stop();
                        console.log(`Stopped track: ${track.kind}`);
                    });
                    mediaStream = null;
                    mediaRecorder = null;
                }
            } else {
                console.log('Page visible again');

                // Auto-reconnect microphone if user had previously granted access
                if (shouldAutoReconnect && !mediaStream && isInitialized) {
                    console.log('Auto-reconnecting microphone...');
                    await setupMicrophone();
                }
            }
        });

        // ============================================================================
        // STARTUP
        // ============================================================================

        window.addEventListener('load', init);
    </script>
</body>
</html>